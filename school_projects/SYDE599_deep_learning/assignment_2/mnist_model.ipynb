{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "# Set up dataset transforms\n",
    "transform = torchvision.transforms.Compose([\n",
    "                           torchvision.transforms.ToTensor(),\n",
    "                           torchvision.transforms.Normalize(0.1307, 0.3081),])\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                           torchvision.transforms.ToTensor(),\n",
    "                           torchvision.transforms.Normalize(0.1307, 0.3081),\n",
    "                           torchvision.transforms.RandomAffine(12, shear=12)])\n",
    "\n",
    "# Set up datasets and dataloaders\n",
    "train_data = torchvision.datasets.MNIST('./datafiles/', train=True, download=True, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "test_data = torchvision.datasets.MNIST('./datafiles/', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, n_unit=None, nc=10, do=0.5, kernel=3, padding='valid', bn2d=True, mp=3, input_shape=28, pool='max', bs=100):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        # Enable or disable batchnorm2d layers\n",
    "        self.bn2d = True if bn2d==1 else False\n",
    "        \n",
    "        # Batch size\n",
    "        self.bs = bs\n",
    "\n",
    "        # First convolutional layer\n",
    "        self.h1 = nn.Conv2d(1, nc, kernel_size=kernel, padding=padding)\n",
    "\n",
    "        # Depending on parameters, use either max or average pooling\n",
    "        if pool == 'max':\n",
    "            self.mp1 = nn.MaxPool2d(mp)\n",
    "            self.mp2 = nn.MaxPool2d(mp)\n",
    "        elif pool == 'avg':\n",
    "            self.mp1 = nn.AvgPool2d(mp)\n",
    "            self.mp2 = nn.AvgPool2d(mp)\n",
    "\n",
    "        self.bn1 =nn.BatchNorm2d(nc)\n",
    "\n",
    "        # Second convolutional layer\n",
    "        self.h2 = nn.Conv2d(nc, nc*5, kernel_size=kernel, padding=padding)\n",
    "        \n",
    "        self.bn2 =nn.BatchNorm2d(nc*5)\n",
    "        \n",
    "        # First linear layer\n",
    "        # Depending on type of padding, adjust next layer expected input dimensions accordingly\n",
    "        if padding=='valid':\n",
    "            self.h3 = nn.Linear(int(nc*5 * np.floor((np.floor(((input_shape - (kernel-1))/mp))-(kernel-1))/mp)**2), 128)\n",
    "        else:\n",
    "            self.h3 = nn.Linear(int(nc*5 * np.floor((np.floor(((input_shape)/mp)))/mp)**2), 128)\n",
    "\n",
    "        self.bn3 =nn.BatchNorm1d(128)\n",
    "        \n",
    "        # Second linear layer\n",
    "        self.h4 = nn.Linear(128, 100)\n",
    "        self.bn4 =nn.BatchNorm1d(100)\n",
    "\n",
    "        # Dropout with dropout rate set by parameters\n",
    "        self.dropout = nn.Dropout(p=do)\n",
    "        # Second linear layer\n",
    "        self.output = nn.Linear(100, 10)\n",
    "\n",
    "    # Forward pass of model\n",
    "    def forward(self, x):\n",
    "        # First convolutional and pooling layer\n",
    "        x = self.h1(x)\n",
    "        x = self.mp1(x)\n",
    "\n",
    "        # If batchnorm2d is enabled and batch size is greater than 1, apply batchnorm\n",
    "        if self.bn2d and self.bs > 1:\n",
    "            x = self.bn1(x)\n",
    "\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Second convolutional and pooling layer\n",
    "        x = self.h2(x)\n",
    "        x = self.mp2(x)\n",
    "\n",
    "        # If batchnorm2d is enabled and batch size is greater than 1, apply batchnorm\n",
    "        if self.bn2d and self.bs > 1:\n",
    "            x = self.bn2(x)\n",
    "\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Flatten input to linear layers\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # First linear layer\n",
    "        x = self.h3(x)\n",
    "\n",
    "        # If batch size > 1, apply batchnorm\n",
    "        if self.bs > 1:\n",
    "            x = self.bn3(x)\n",
    "\n",
    "        # Second linear layer\n",
    "        x = self.h4(x)\n",
    "\n",
    "        # If batch size > 1, apply batchnorm\n",
    "        if self.bs > 1:\n",
    "            x = self.bn4(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return self.output(x)\n",
    "\n",
    "# Train the model\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predictions = outputs.argmax(dim=1, keepdim=True)\n",
    "        correct += predictions.eq(targets.view_as(predictions)).sum()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Epoch: {} {}/{} Training loss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(inputs),\n",
    "                len(train_loader.dataset),\n",
    "                loss))\n",
    "\n",
    "    print('Training loss: {:.6f}; Training accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        total_loss / len(train_loader.dataset) * len(inputs),\n",
    "        correct,\n",
    "        len(train_loader.dataset),\n",
    "        100. * correct / len(train_loader.dataset)))\n",
    "    \n",
    "    return total_loss / len(train_loader.dataset) * len(inputs), 100. * correct / len(train_loader.dataset)\n",
    "\n",
    "# Test the model\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss += nn.CrossEntropyLoss()(outputs, targets)\n",
    "            predictions = outputs.argmax(dim=1, keepdim=True)\n",
    "            correct += predictions.eq(targets.view_as(predictions)).sum()\n",
    "\n",
    "    loss = loss / len(test_loader.dataset) * len(inputs)\n",
    "\n",
    "    print('Test loss: {:.6f}; Test accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        loss,\n",
    "        correct,\n",
    "        len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return loss, 100. * correct / len(test_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "def run(params=None):\n",
    "    train_data = torchvision.datasets.MNIST('./datafiles/', train=True, download=True, transform=transform_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=params['batch_size'], shuffle=True)\n",
    "\n",
    "    test_data = torchvision.datasets.MNIST('./datafiles/', train=False, download=True, transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=params['batch_size'], shuffle=True)\n",
    "    \n",
    "    #model = Network(params['nodes'])\n",
    "    model = Network(do=params['dropout'], kernel=params['kernel_size'], padding=params['padding'], bn2d=params['batchnorm2d'], mp=params['pool_size'], pool=params['pooling'], bs=params['batch_size'])\n",
    "\n",
    "    if params:\n",
    "        optimizer = getattr(optim, params['optimizer'])(model.parameters(), lr= params['learning_rate'])\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "\n",
    "    EPOCHS = 10\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    for epoch in range(0, EPOCHS):\n",
    "        tr_loss, tr_acc = train(model, train_loader, optimizer, epoch)\n",
    "        train_loss.append(tr_loss.detach().numpy())\n",
    "        train_acc.append(tr_acc)\n",
    "\n",
    "        test_loss, test_acc = test(model, test_loader)\n",
    "        val_loss.append(test_loss.detach().numpy())\n",
    "        val_acc.append(test_acc.detach().numpy())\n",
    "\n",
    "    return val_acc[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-03 13:10:15,261]\u001b[0m A new study created in memory with name: no-name-a2a80a60-34e2-43d0-9fbb-7ee63a129838\u001b[0m\n",
      "C:\\Users\\Tia\\AppData\\Local\\Temp\\ipykernel_8696\\655387829.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "c:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [1, 100] and step=10, but the range is not divisible by `step`. It will be replaced by [1, 91].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tia\\AppData\\Local\\Temp\\ipykernel_8696\\655387829.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'batchnorm2d': trial.suggest_discrete_uniform(\"batchnorm2d\", 0, 1, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 0/60000 Training loss: 2.742836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2022-11-03 13:10:23,168]\u001b[0m Trial 0 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Tia\\AppData\\Local\\Temp\\ipykernel_8696\\655387829.py\", line 20, in objective\n",
      "    accuracy = run(params)\n",
      "  File \"C:\\Users\\Tia\\AppData\\Local\\Temp\\ipykernel_8696\\713351247.py\", line 28, in run\n",
      "    tr_loss, tr_acc = train(model, train_loader, optimizer, epoch)\n",
      "  File \"C:\\Users\\Tia\\AppData\\Local\\Temp\\ipykernel_8696\\3290242296.py\", line 92, in train\n",
      "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
      "  File \"c:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 521, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"c:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 561, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"c:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"c:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"c:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torchvision\\datasets\\mnist.py\", line 134, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"c:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torchvision\\transforms\\transforms.py\", line 61, in __call__\n",
      "    img = t(img)\n",
      "  File \"c:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torchvision\\transforms\\transforms.py\", line 1466, in forward\n",
      "    return F.affine(img, *ret, interpolation=self.interpolation, fill=fill)\n",
      "  File \"c:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torchvision\\transforms\\functional.py\", line 1125, in affine\n",
      "    return F_t.affine(img, matrix=matrix, interpolation=interpolation.value, fill=fill)\n",
      "  File \"c:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py\", line 698, in affine\n",
      "    return _apply_grid_transform(img, grid, interpolation, fill=fill)\n",
      "  File \"c:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py\", line 647, in _apply_grid_transform\n",
      "    img = grid_sample(img, grid, mode=mode, padding_mode=\"zeros\", align_corners=False)\n",
      "  File \"c:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torch\\nn\\functional.py\", line 4011, in grid_sample\n",
      "    return torch.grid_sampler(input, grid, mode_enum, padding_mode_enum, align_corners)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tia\\Documents\\University\\MASc\\F22\\SYDE599\\syde599\\A2\\mnist_model.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m accuracy\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m, sampler\u001b[39m=\u001b[39moptuna\u001b[39m.\u001b[39msamplers\u001b[39m.\u001b[39mTPESampler())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\optuna\\study\\study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     _optimize(\n\u001b[0;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    429\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\optuna\\study\\_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    233\u001b[0m ):\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32mc:\\Users\\Tia\\Documents\\University\\MASc\\F22\\SYDE599\\syde599\\A2\\mnist_model.ipynb Cell 4\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective\u001b[39m(trial):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     params \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_loguniform(\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1e-5\u001b[39m, \u001b[39m1e-1\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m               \u001b[39m'\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_categorical(\u001b[39m\"\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m\"\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39mAdam\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mRMSprop\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSGD\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mkernel_size\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_int(\u001b[39m\"\u001b[39m\u001b[39mkernel_size\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m               }\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     accuracy \u001b[39m=\u001b[39m run(params)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m accuracy\n",
      "\u001b[1;32mc:\\Users\\Tia\\Documents\\University\\MASc\\F22\\SYDE599\\syde599\\A2\\mnist_model.ipynb Cell 4\u001b[0m in \u001b[0;36mrun\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m use_cuda \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, EPOCHS):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     tr_loss, tr_acc \u001b[39m=\u001b[39m train(model, train_loader, optimizer, epoch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     train_loss\u001b[39m.\u001b[39mappend(tr_loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     train_acc\u001b[39m.\u001b[39mappend(tr_acc)\n",
      "\u001b[1;32mc:\\Users\\Tia\\Documents\\University\\MASc\\F22\\SYDE599\\syde599\\A2\\mnist_model.ipynb Cell 4\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (inputs, targets) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tia/Documents/University/MASc/F22/SYDE599/syde599/A2/mnist_model.ipynb#W5sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 521\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    522\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    523\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    524\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    525\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    560\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    562\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    563\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torchvision\\datasets\\mnist.py:134\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    131\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 134\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    136\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torchvision\\transforms\\transforms.py:61\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     60\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 61\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     62\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torchvision\\transforms\\transforms.py:1466\u001b[0m, in \u001b[0;36mRandomAffine.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m   1462\u001b[0m img_size \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mget_image_size(img)\n\u001b[0;32m   1464\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdegrees, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranslate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshear, img_size)\n\u001b[1;32m-> 1466\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49maffine(img, \u001b[39m*\u001b[39;49mret, interpolation\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation, fill\u001b[39m=\u001b[39;49mfill)\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torchvision\\transforms\\functional.py:1125\u001b[0m, in \u001b[0;36maffine\u001b[1;34m(img, angle, translate, scale, shear, interpolation, fill, resample, fillcolor)\u001b[0m\n\u001b[0;32m   1123\u001b[0m translate_f \u001b[39m=\u001b[39m [\u001b[39m1.0\u001b[39m \u001b[39m*\u001b[39m t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m translate]\n\u001b[0;32m   1124\u001b[0m matrix \u001b[39m=\u001b[39m _get_inverse_affine_matrix([\u001b[39m0.0\u001b[39m, \u001b[39m0.0\u001b[39m], angle, translate_f, scale, shear)\n\u001b[1;32m-> 1125\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39;49maffine(img, matrix\u001b[39m=\u001b[39;49mmatrix, interpolation\u001b[39m=\u001b[39;49minterpolation\u001b[39m.\u001b[39;49mvalue, fill\u001b[39m=\u001b[39;49mfill)\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py:698\u001b[0m, in \u001b[0;36maffine\u001b[1;34m(img, matrix, interpolation, fill)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[39m# grid will be generated on the same device as theta and img\u001b[39;00m\n\u001b[0;32m    697\u001b[0m grid \u001b[39m=\u001b[39m _gen_affine_grid(theta, w\u001b[39m=\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], h\u001b[39m=\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], ow\u001b[39m=\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], oh\u001b[39m=\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m])\n\u001b[1;32m--> 698\u001b[0m \u001b[39mreturn\u001b[39;00m _apply_grid_transform(img, grid, interpolation, fill\u001b[39m=\u001b[39;49mfill)\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py:647\u001b[0m, in \u001b[0;36m_apply_grid_transform\u001b[1;34m(img, grid, mode, fill)\u001b[0m\n\u001b[0;32m    644\u001b[0m     dummy \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones((img\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m, img\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m], img\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m]), dtype\u001b[39m=\u001b[39mimg\u001b[39m.\u001b[39mdtype, device\u001b[39m=\u001b[39mimg\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    645\u001b[0m     img \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((img, dummy), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 647\u001b[0m img \u001b[39m=\u001b[39m grid_sample(img, grid, mode\u001b[39m=\u001b[39;49mmode, padding_mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mzeros\u001b[39;49m\u001b[39m\"\u001b[39;49m, align_corners\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    649\u001b[0m \u001b[39m# Fill with required color\u001b[39;00m\n\u001b[0;32m    650\u001b[0m \u001b[39mif\u001b[39;00m fill \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Tia\\Anaconda3\\envs\\deepenv\\lib\\site-packages\\torch\\nn\\functional.py:4011\u001b[0m, in \u001b[0;36mgrid_sample\u001b[1;34m(input, grid, mode, padding_mode, align_corners)\u001b[0m\n\u001b[0;32m   4003\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   4004\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDefault grid_sample and affine_grid behavior has changed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4005\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto align_corners=False since 1.3.0. Please specify \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4006\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39malign_corners=True if the old behavior is desired. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4007\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee the documentation of grid_sample for details.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4008\u001b[0m     )\n\u001b[0;32m   4009\u001b[0m     align_corners \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 4011\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mgrid_sampler(\u001b[39minput\u001b[39;49m, grid, mode_enum, padding_mode_enum, align_corners)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna import trial\n",
    "\n",
    "# Set up parameters for Optuna to optimize\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "              'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "              'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
    "              'padding': trial.suggest_categorical(\"padding\", [\"valid\", \"same\"]),\n",
    "              'pooling': trial.suggest_categorical(\"pooling\", [\"max\", \"avg\"]),\n",
    "              'batch_size': trial.suggest_int(\"batch_size\", 1, 100, step=10),\n",
    "              'pool_size': trial.suggest_int(\"pool_size\", 1, 3),\n",
    "              'dropout': trial.suggest_float(\"dropout\", 0.2, 0.8),\n",
    "              'batchnorm2d': trial.suggest_discrete_uniform(\"batchnorm2d\", 0, 1, 1),\n",
    "              'num_channel': trial.suggest_int(\"num_channel\", 10, 100),\n",
    "              'kernel_size': trial.suggest_int(\"kernel_size\", 1, 3),\n",
    "              }\n",
    "    \n",
    "\n",
    "    accuracy = run(params)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Run Optuna trials\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Best Optuna trial\n",
    "best_trial = study.best_trial\n",
    "\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "\n",
    "# Save the Optuna trials\n",
    "with open(\"study.pkl\",\"wb\") as f:\n",
    "    pickle.dump(study, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 28, 28]             100\n",
      "         MaxPool2d-2           [-1, 10, 14, 14]               0\n",
      "            Conv2d-3           [-1, 50, 14, 14]           4,550\n",
      "         MaxPool2d-4             [-1, 50, 7, 7]               0\n",
      "            Linear-5                  [-1, 128]         313,728\n",
      "       BatchNorm1d-6                  [-1, 128]             256\n",
      "            Linear-7                  [-1, 100]          12,900\n",
      "       BatchNorm1d-8                  [-1, 100]             200\n",
      "           Dropout-9                  [-1, 100]               0\n",
      "           Linear-10                   [-1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 332,744\n",
      "Trainable params: 332,744\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.17\n",
      "Params size (MB): 1.27\n",
      "Estimated Total Size (MB): 1.44\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "params =  {'learning_rate': 0.0018709287702689723, 'optimizer': 'Adam', 'padding': 'same', 'pooling': 'max', 'batch_size': 101, 'pool_size': 2, 'dropout': 0.27587651756009146, 'batchnorm2d': 0.0, 'num_channel': 35, 'kernel_size': 3}\n",
    "\n",
    "model = Network(do=params['dropout'], kernel=params['kernel_size'], padding=params['padding'], bn2d=params['batchnorm2d'], mp=params['pool_size'], pool=params['pooling'], bs=params['batch_size'])\n",
    "\n",
    "# Print summary for model with optimized parameters\n",
    "summary(model, (1,28,28))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deepenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57b1a6f252fb2b7967a04b62771246b49ca108f8b90a576903f9d66029559da6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

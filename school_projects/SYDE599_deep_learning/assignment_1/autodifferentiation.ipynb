{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4204c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5e297f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for fully connected multi-layer perceptron\n",
    "# Inputs:\n",
    "# layers - list of layers with number of nodes in that layer at the element. \n",
    "#          Creates a network with length(layers) layers.\n",
    "#\n",
    "# activations - list of 0s or 1s, of same length as the layers variable. \n",
    "#               0 means no ReLU at the layer and 1 means ReLU is present at that layer\n",
    "#\n",
    "# binClass - boolean for whether the model is performing binary classification or regression\n",
    "class MLP():\n",
    "    def __init__(self, layers, relu_activations, binClass=False):\n",
    "        self.weights = np.empty(len(layers)-1,object)\n",
    "        self.bias = np.empty(len(layers)-1,object)\n",
    "        self.relu_activations = relu_activations\n",
    "        self.binClass = binClass\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            self.weights[i] = np.random.randn(layers[i],layers[i+1])\n",
    "            self.bias[i] = np.random.randn(layers[i+1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        for i in range(len(self.weights)):\n",
    "            print(i)\n",
    "            print(x)\n",
    "            print(self.weights[i])\n",
    "            print(self.bias[i])\n",
    "            x = np.matmul(x,self.weights[i])\n",
    "            \n",
    "            x += self.bias[i]\n",
    "            \n",
    "          \n",
    "            if self.relu_activations[i]:\n",
    "                x = self.ReLU(x)\n",
    "                \n",
    "        if self.binClass:\n",
    "            x = self.sigmoid(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def backwards(self, y_hat, y):\n",
    "        delta_k = y_hat - y\n",
    "        pass\n",
    "    \n",
    "    def ReLU(self, x):\n",
    "        return np.maximum(0,x)\n",
    "    \n",
    "    def ReLU_deriv(self,x):\n",
    "        pass\n",
    "            \n",
    "    def sigmoid(self, x):\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_deriv(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        y_hat = self.forward(x)\n",
    "        return (0.5*((y_hat-y)**2)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c0ecf557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for fully connected multi-layer perceptron\n",
    "# Inputs:\n",
    "# layers - list of layers with number of nodes in that layer at the element. \n",
    "#          Creates a network with length(layers) layers.\n",
    "#\n",
    "# activations - list of 0s or 1s, of same length as the layers variable. \n",
    "#               0 means no ReLU at the layer and 1 means ReLU is present at that layer\n",
    "#\n",
    "# binClass - boolean for whether the model is performing binary classification or regression\n",
    "class MLP2():\n",
    "    def __init__(self, layers, relu_activations, binClass=False):\n",
    "        self.weights = np.empty(len(layers)-1,object)\n",
    "        self.relu_activations = relu_activations\n",
    "        self.binClass = binClass\n",
    "        self.activations = np.array([])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            self.weights[i] = np.random.randn(layers[i]+1,layers[i+1])\n",
    "           \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # assume x is dimensions [size x input]\n",
    "        # declare activations data type\n",
    "        self.activations = [np.atleast_2d(x)]\n",
    "        \n",
    "        for i in range(len(self.weights)):\n",
    "            \n",
    "            #add extra input for bias term\n",
    "            new_x = np.ones((x.shape[0], x.shape[1]+1))\n",
    "            new_x[:,0:x.shape[1]] = x\n",
    "            x = new_x\n",
    "            \n",
    "            print(i)\n",
    "            print(x)\n",
    "            print(self.weights[i])\n",
    "        \n",
    "            x = np.matmul(x,self.weights[i])\n",
    "          \n",
    "            if self.relu_activations[i]:\n",
    "                x = self.ReLU(x)\n",
    "            \n",
    "            #append activations for use in backprop\n",
    "            self.activations.append(x)\n",
    "            print(x.shape)\n",
    "                \n",
    "        if self.binClass:\n",
    "            x = self.sigmoid(x)\n",
    "            self.activations[-1] = x\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def backwards(self, y_hat, y):\n",
    "        delta_k = y_hat - y\n",
    "        deltas = [delta_k]\n",
    "        if self.binClass:\n",
    "            deltas = [delta_k*self.sigmoid_deriv(self.activations[-1])]\n",
    "        \n",
    "        for layer in np.arange(len(self.layers)-2,0,-1):\n",
    "            delta = np.matmul(deltas[-1], self.weights[layer].T)\n",
    "            if self.relu_activations[layer]:\n",
    "                delta = delta*self.ReLU_deriv(self.activations[layer])\n",
    "                \n",
    "            deltas.append(delta)\n",
    "            \n",
    "        pass\n",
    "    \n",
    "    def ReLU(self, x):\n",
    "        return np.maximum(0,x)\n",
    "    \n",
    "    def ReLU_deriv(self,x):\n",
    "        pass\n",
    "            \n",
    "    def sigmoid(self, x):\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_deriv(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        y_hat = self.forward(x)\n",
    "        return (0.5*((y_hat-y)**2)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f3f88803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[1. 2. 1.]\n",
      " [1. 1. 1.]]\n",
      "[[-0.41598427 -1.92823029  0.78107452  0.71436282  0.74822889  1.98629135\n",
      "  -1.00198731  0.26866794 -0.77436818  1.0688745 ]\n",
      " [-0.26031275 -1.11211735 -1.27896518 -1.0245235  -0.12817337  0.4572856\n",
      "  -0.58256769 -0.09070672 -1.34542514 -0.0459555 ]\n",
      " [-0.52459004  0.19192151  0.64176929  1.35838524 -0.07778525 -0.19920693\n",
      "   0.44797642  0.13599888 -0.82386014  0.15869438]]\n",
      "(2, 10)\n",
      "1\n",
      "[[0.         0.         0.         0.02370105 0.41409691 2.70165563\n",
      "  0.         0.22325337 0.         1.13565789 1.        ]\n",
      " [0.         0.         0.14387863 1.04822455 0.54227027 2.24437002\n",
      "  0.         0.3139601  0.         1.18161339 1.        ]]\n",
      "[[ 8.65457458e-01  5.05815622e-01  2.33389953e+00 -1.98542357e+00\n",
      "  -4.59566320e-02  1.83676053e-04 -5.18310265e-01 -3.77156624e-01\n",
      "  -1.62603257e+00 -1.30558888e+00]\n",
      " [ 5.90279876e-01 -8.60789648e-01 -3.90536655e-01 -1.45712486e-01\n",
      "  -4.12724441e-01 -4.50474060e-01 -6.83837265e-01  7.10099619e-01\n",
      "  -2.03119606e+00  8.10266848e-01]\n",
      " [ 1.05238360e+00 -6.95999456e-02 -3.72603396e-01  1.36734040e+00\n",
      "   3.48655460e-01  1.03148847e+00 -5.11663553e-01  1.92053587e+00\n",
      "  -4.84199702e-01 -1.13881699e+00]\n",
      " [ 1.13211301e+00  2.93358038e-01 -6.20502730e-01 -6.44012914e-01\n",
      "  -6.37198160e-01  3.75304019e-01  3.05025983e+00 -1.45701134e+00\n",
      "   7.96275797e-01  7.15674046e-01]\n",
      " [-1.79956409e-01  1.35432993e+00 -9.38519342e-02  4.74520605e-01\n",
      "  -8.58574080e-02 -4.06499344e-01 -1.15949773e-01 -3.64654325e-01\n",
      "  -5.64782672e-01  4.95893937e-01]\n",
      " [ 1.77958184e+00 -4.03274928e-01 -1.97726508e+00 -3.35931132e-01\n",
      "  -4.42538163e-01  2.55471085e+00 -1.07420181e+00  1.34892961e+00\n",
      "  -3.93017128e-02  3.57392005e-01]\n",
      " [-1.81362721e-01 -2.71018949e-01 -5.89491210e-01 -7.51254036e-01\n",
      "   1.15606200e+00  1.44919795e+00 -6.12167531e-01 -6.65535345e-02\n",
      "  -7.46461430e-01  3.50312468e-01]\n",
      " [ 3.71351716e-01  1.56910642e+00  1.26405728e+00  1.56362633e+00\n",
      "   6.68809958e-01 -2.02610764e+00  2.42042156e-01 -4.18269364e-01\n",
      "   9.28488753e-01  1.06355514e-01]\n",
      " [ 5.36276589e-01  1.27515817e+00 -4.28425718e-01  2.90433793e-01\n",
      "  -3.30817798e-02  1.51603349e+00 -9.69745450e-01 -2.93015482e-01\n",
      "  -1.58695830e+00  1.10188767e+00]\n",
      " [ 1.58956114e-01  4.25875797e-01 -2.72735084e+00 -9.56832780e-01\n",
      "   1.03796663e-01  1.26606836e+00  4.00456654e-01 -2.43147596e-01\n",
      "   1.26116185e+00  8.94125747e-01]\n",
      " [-2.48690612e-01  2.06748566e+00  7.95722872e-01  6.70504510e-01\n",
      "   1.19979144e+00  1.74284981e-01 -1.25779090e+00  9.52366569e-01\n",
      "   8.92978935e-01 -1.25935015e+00]]\n",
      "(2, 10)\n",
      "2\n",
      "[[4.77486484 2.37970993 0.         0.         0.22074175 7.90228407\n",
      "  0.         4.04166236 2.21133371 0.96767554 1.        ]\n",
      " [5.29030297 3.19014886 0.         0.         0.         7.08926734\n",
      "  0.         2.1125452  3.04523049 1.48791632 1.        ]]\n",
      "[[ 1.74043119]\n",
      " [-0.88073584]\n",
      " [ 1.02973149]\n",
      " [ 1.00031406]\n",
      " [ 0.61854547]\n",
      " [ 0.18153187]\n",
      " [ 0.85564407]\n",
      " [-1.02379849]\n",
      " [-0.66487103]\n",
      " [-0.99978773]\n",
      " [-0.30456658]]\n",
      "(2, 1)\n",
      "[[0.90534689]\n",
      " [1.70498469]]\n"
     ]
    }
   ],
   "source": [
    "test = MLP2([2, 10, 10, 1],[1, 1, 0])\n",
    "tester = np.array([[1,2],[1,1]])\n",
    "wow = test.forward(tester)\n",
    "print(wow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587e8f55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

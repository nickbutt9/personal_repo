{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a38c13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c444b3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['norm_fog_data/001_task_1.csv', 'norm_fog_data/001_task_2.csv', 'norm_fog_data/001_task_3.csv', 'norm_fog_data/001_task_4.csv', 'norm_fog_data/002_task_1.csv', 'norm_fog_data/002_task_2.csv', 'norm_fog_data/002_task_3.csv', 'norm_fog_data/002_task_4.csv', 'norm_fog_data/003_task_1.csv', 'norm_fog_data/003_task_2.csv', 'norm_fog_data/003_task_3.csv', 'norm_fog_data/003_task_4.csv', 'norm_fog_data/004_task_1.csv', 'norm_fog_data/004_task_2.csv', 'norm_fog_data/004_task_3.csv', 'norm_fog_data/004_task_4.csv', 'norm_fog_data/004_task_5.csv', 'norm_fog_data/005_task_1.csv', 'norm_fog_data/005_task_2.csv', 'norm_fog_data/005_task_3.csv', 'norm_fog_data/005_task_4.csv', 'norm_fog_data/006_task_1.csv', 'norm_fog_data/006_task_2.csv', 'norm_fog_data/006_task_3.csv', 'norm_fog_data/006_task_4.csv', 'norm_fog_data/007_task_1.csv', 'norm_fog_data/007_task_2.csv', 'norm_fog_data/007_task_3.csv', 'norm_fog_data/007_task_4.csv', 'norm_fog_data/008_task_1.csv', 'norm_fog_data/008_task_2.csv', 'norm_fog_data/008_task_3.csv', 'norm_fog_data/008_task_4.csv', 'norm_fog_data/008_task_5.csv', 'norm_fog_data/008_task_6.csv', 'norm_fog_data/008_task_7.csv', 'norm_fog_data/008_task_8.csv', 'norm_fog_data/008_task_9.csv', 'norm_fog_data/009_task_1.csv', 'norm_fog_data/009_task_2.csv', 'norm_fog_data/009_task_3.csv', 'norm_fog_data/009_task_4.csv', 'norm_fog_data/009_task_5.csv', 'norm_fog_data/009_task_6.csv', 'norm_fog_data/010_task_1.csv', 'norm_fog_data/010_task_2.csv', 'norm_fog_data/010_task_3.csv', 'norm_fog_data/010_task_4.csv', 'norm_fog_data/011_task_1.csv', 'norm_fog_data/011_task_2.csv', 'norm_fog_data/011_task_3.csv', 'norm_fog_data/011_task_4.csv', 'norm_fog_data/012_task_1.csv', 'norm_fog_data/012_task_2.csv', 'norm_fog_data/012_task_3.csv', 'norm_fog_data/012_task_4.csv']\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "pre = 'norm_fog_data/'\n",
    "tasks = ['1','2','3','4','5','6','7','8','9']\n",
    "prefixes = ['001', '002', '003', '004', '005', '006', '007', '008', '009','010','011','012']\n",
    "filenames = []\n",
    "for prefix in prefixes:\n",
    "    if prefix not in ['004','008','009']:\n",
    "        for task in tasks[:4]:\n",
    "            file = pre + prefix + '_task_' + task + '.csv'\n",
    "            filenames.append(file)      \n",
    "    elif prefix == '004':\n",
    "        for task in tasks[:5]:\n",
    "            file = pre + prefix + '_task_' + task + '.csv'\n",
    "            filenames.append(file)\n",
    "    elif prefix == '008':\n",
    "        for task in tasks:\n",
    "            file = pre + prefix + '_task_' + task + '.csv'\n",
    "            filenames.append(file)\n",
    "    else:\n",
    "        for task in tasks[:6]:\n",
    "            file = pre + prefix + '_task_' + task + '.csv'\n",
    "            filenames.append(file)\n",
    "\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e22ef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding  norm_fog_data/001_task_1.csv  to test set\n",
      "Adding  norm_fog_data/001_task_2.csv  to test set\n",
      "Adding  norm_fog_data/001_task_3.csv  to test set\n",
      "Adding  norm_fog_data/001_task_4.csv  to test set\n",
      "Adding  norm_fog_data/002_task_1.csv  to training set\n",
      "Adding  norm_fog_data/002_task_2.csv  to training set\n",
      "Adding  norm_fog_data/002_task_3.csv  to training set\n",
      "Adding  norm_fog_data/002_task_4.csv  to training set\n",
      "Adding  norm_fog_data/003_task_1.csv  to training set\n",
      "Adding  norm_fog_data/003_task_2.csv  to training set\n",
      "Adding  norm_fog_data/003_task_3.csv  to training set\n",
      "Adding  norm_fog_data/003_task_4.csv  to training set\n",
      "Adding  norm_fog_data/004_task_1.csv  to training set\n",
      "Adding  norm_fog_data/004_task_2.csv  to training set\n",
      "Adding  norm_fog_data/004_task_3.csv  to training set\n",
      "Adding  norm_fog_data/004_task_4.csv  to training set\n",
      "Adding  norm_fog_data/004_task_5.csv  to training set\n",
      "Adding  norm_fog_data/005_task_1.csv  to test set\n",
      "Adding  norm_fog_data/005_task_2.csv  to test set\n",
      "Adding  norm_fog_data/005_task_3.csv  to test set\n",
      "Adding  norm_fog_data/005_task_4.csv  to test set\n",
      "Adding  norm_fog_data/006_task_1.csv  to training set\n",
      "Adding  norm_fog_data/006_task_2.csv  to training set\n",
      "Adding  norm_fog_data/006_task_3.csv  to training set\n",
      "Adding  norm_fog_data/006_task_4.csv  to training set\n",
      "Adding  norm_fog_data/007_task_1.csv  to test set\n",
      "Adding  norm_fog_data/007_task_2.csv  to test set\n",
      "Adding  norm_fog_data/007_task_3.csv  to test set\n",
      "Adding  norm_fog_data/007_task_4.csv  to test set\n",
      "Adding  norm_fog_data/008_task_1.csv  to training set\n",
      "Adding  norm_fog_data/008_task_2.csv  to training set\n",
      "Adding  norm_fog_data/008_task_3.csv  to training set\n",
      "Adding  norm_fog_data/008_task_4.csv  to training set\n",
      "Adding  norm_fog_data/008_task_5.csv  to training set\n",
      "Adding  norm_fog_data/008_task_6.csv  to training set\n",
      "Adding  norm_fog_data/008_task_7.csv  to training set\n",
      "Adding  norm_fog_data/008_task_8.csv  to training set\n",
      "Adding  norm_fog_data/008_task_9.csv  to training set\n",
      "Adding  norm_fog_data/009_task_1.csv  to training set\n",
      "Adding  norm_fog_data/009_task_2.csv  to training set\n",
      "Adding  norm_fog_data/009_task_3.csv  to training set\n",
      "Adding  norm_fog_data/009_task_4.csv  to training set\n",
      "Adding  norm_fog_data/009_task_5.csv  to training set\n",
      "Adding  norm_fog_data/009_task_6.csv  to training set\n",
      "Adding  norm_fog_data/010_task_1.csv  to training set\n",
      "Adding  norm_fog_data/010_task_2.csv  to training set\n",
      "Adding  norm_fog_data/010_task_3.csv  to training set\n",
      "Adding  norm_fog_data/010_task_4.csv  to training set\n",
      "Adding  norm_fog_data/011_task_1.csv  to training set\n",
      "Adding  norm_fog_data/011_task_2.csv  to training set\n",
      "Adding  norm_fog_data/011_task_3.csv  to training set\n",
      "Adding  norm_fog_data/011_task_4.csv  to training set\n",
      "Adding  norm_fog_data/012_task_1.csv  to training set\n",
      "Adding  norm_fog_data/012_task_2.csv  to training set\n",
      "Adding  norm_fog_data/012_task_3.csv  to training set\n",
      "Adding  norm_fog_data/012_task_4.csv  to training set\n",
      "10677 1745\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Use patient 1 and 5 as test set\n",
    "# Start with window size of 1s\n",
    "train = np.empty((10677,500,32))\n",
    "test = np.empty((1745,500,32))\n",
    "train_counter = 0\n",
    "test_counter = 0\n",
    "train_1s_windows = 0\n",
    "test_1s_windows = 0\n",
    "for file in filenames:\n",
    "    if file[14:17] not in ['001','005','007']:\n",
    "        print('Adding ', file, ' to training set')\n",
    "        df = pd.read_csv(file)\n",
    "        data = np.array(df)\n",
    "        data = data[:data.shape[0]-1,:]\n",
    "        data = data.reshape((-1,500,32))\n",
    "        train[train_counter:train_counter+data.shape[0]] = data\n",
    "        train_counter += data.shape[0]\n",
    "        length = data.shape[0]\n",
    "        train_1s_windows += int((length))\n",
    "    else:\n",
    "        print('Adding ', file, ' to test set')\n",
    "        df = pd.read_csv(file)\n",
    "        data = np.array(df)\n",
    "        data = data[:data.shape[0]-1,:]\n",
    "        data = data.reshape((-1,500,32))\n",
    "        test[test_counter:test_counter+data.shape[0]] = data\n",
    "        test_counter += data.shape[0]\n",
    "        length = data.shape[0]\n",
    "        test_1s_windows += int((length))\n",
    "\n",
    "print(train_1s_windows, test_1s_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a1ee953",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "np.random.shuffle(train)\n",
    "np.random.shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aa84331",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob, fc_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        # RNN layers\n",
    "        self.rnn = nn.RNN(\n",
    "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
    "        )\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(fc_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out, h0 = self.rnn(x)\n",
    "\n",
    "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
    "        out = self.fc(out.flatten(start_dim=-2))\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc25c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob, fc_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
    "        )\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(fc_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "\n",
    "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
    "        out = self.fc(out.flatten(start_dim=-2))\n",
    "\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0228fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob, fc_dim):\n",
    "        super(GRUModel, self).__init__()\n",
    "\n",
    "        # GRU layers\n",
    "        self.gru = nn.GRU(\n",
    "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
    "        )\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(fc_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out, _ = self.gru(x)\n",
    "\n",
    "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
    "        out = self.fc(out.flatten(start_dim=-2))\n",
    "\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "850cd75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch:  0\n",
      "Training loss:  tensor(0.6863, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.5576)\n",
      "Test Accuracy:  tensor(0.6602)\n",
      "Starting epoch:  1\n",
      "Training loss:  tensor(0.6661, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.5978)\n",
      "Test Accuracy:  tensor(0.6510)\n",
      "Starting epoch:  2\n",
      "Training loss:  tensor(0.5702, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.7264)\n",
      "Test Accuracy:  tensor(0.7060)\n",
      "Starting epoch:  3\n",
      "Training loss:  tensor(0.4833, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.7750)\n",
      "Test Accuracy:  tensor(0.7278)\n",
      "Starting epoch:  4\n",
      "Training loss:  tensor(0.4704, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.7841)\n",
      "Test Accuracy:  tensor(0.7318)\n"
     ]
    }
   ],
   "source": [
    "# Vanilla RNN 1\n",
    "input_dim = 30\n",
    "hidden_dim = 1 \n",
    "layer_dim = 2 \n",
    "output_dim = 1 \n",
    "dropout_prob = 0\n",
    "fc_dim = 500\n",
    "rnn = RNNModel(input_dim, hidden_dim, layer_dim, output_dim, dropout_prob, fc_dim)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(),lr=1e-2,weight_decay=0)\n",
    "rnn.double()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "# Train\n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    for epoch in range(5):\n",
    "        rnn.train()\n",
    "        print('Starting epoch: ', epoch)\n",
    "        running_loss = 0\n",
    "        for i in range(0, train.shape[0], 64):\n",
    "            optimizer.zero_grad()\n",
    "            data = train[i:i+64]\n",
    "            y = data[:,:,1]\n",
    "            y[y<0] = 0\n",
    "            y[y>0] = 1\n",
    "            y = y.mean(axis=1)\n",
    "            y = np.round_(y)\n",
    "            y = torch.tensor(y)\n",
    "            input = torch.tensor(data[:,:,2:])\n",
    "            output = rnn(input)\n",
    "            loss = criterion(output.flatten(), y)\n",
    "            loss.backward()     \n",
    "            optimizer.step()\n",
    "            \n",
    "        running_loss = test_model(rnn, 'train loss')\n",
    "        train_accuracy = test_model(rnn, 'train accuracy')\n",
    "        test_accuracy = test_model(rnn, 'test accuracy')\n",
    "        train_loss.append(train_accuracy)\n",
    "        test_loss.append(test_accuracy)\n",
    "        print('Training loss: ', running_loss)\n",
    "        print('Training Accuracy: ', train_accuracy)\n",
    "        print('Test Accuracy: ', test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42dec528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch:  0\n",
      "Training loss:  tensor(0.5782, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.7093)\n",
      "Test Accuracy:  tensor(0.6974)\n",
      "Starting epoch:  1\n",
      "Training loss:  tensor(0.5014, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.7672)\n",
      "Test Accuracy:  tensor(0.7186)\n",
      "Starting epoch:  2\n",
      "Training loss:  tensor(0.4798, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.7751)\n",
      "Test Accuracy:  tensor(0.7129)\n",
      "Starting epoch:  3\n",
      "Training loss:  tensor(0.4840, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.7757)\n",
      "Test Accuracy:  tensor(0.7307)\n",
      "Starting epoch:  4\n",
      "Training loss:  tensor(0.4778, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.7783)\n",
      "Test Accuracy:  tensor(0.7192)\n"
     ]
    }
   ],
   "source": [
    "# Vanilla RNN 1\n",
    "input_dim = 30\n",
    "hidden_dim = 1 \n",
    "layer_dim = 3 \n",
    "output_dim = 1 \n",
    "dropout_prob = 0\n",
    "fc_dim = 500\n",
    "rnn = RNNModel(input_dim, hidden_dim, layer_dim, output_dim, dropout_prob, fc_dim)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(),lr=1e-2,weight_decay=0)\n",
    "rnn.double()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "# Train\n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    for epoch in range(5):\n",
    "        rnn.train()\n",
    "        print('Starting epoch: ', epoch)\n",
    "        running_loss = 0\n",
    "        for i in range(0, train.shape[0], 64):\n",
    "            optimizer.zero_grad()\n",
    "            data = train[i:i+64]\n",
    "            y = data[:,:,1]\n",
    "            y[y<0] = 0\n",
    "            y[y>0] = 1\n",
    "            y = y.mean(axis=1)\n",
    "            y = np.round_(y)\n",
    "            y = torch.tensor(y)\n",
    "            input = torch.tensor(data[:,:,2:])\n",
    "            output = rnn(input)\n",
    "            loss = criterion(output.flatten(), y)\n",
    "            loss.backward()     \n",
    "            optimizer.step()\n",
    "            \n",
    "        running_loss = test_model(rnn, 'train loss')\n",
    "        train_accuracy = test_model(rnn, 'train accuracy')\n",
    "        test_accuracy = test_model(rnn, 'test accuracy')\n",
    "        train_loss.append(train_accuracy)\n",
    "        test_loss.append(test_accuracy)\n",
    "        print('Training loss: ', running_loss)\n",
    "        print('Training Accuracy: ', train_accuracy)\n",
    "        print('Test Accuracy: ', test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7bf76",
   "metadata": {},
   "source": [
    "Vanilla RNN 1 Results: training loss - 0.4704, training accuracy - 0.7841, test accuracy - 0.7318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aa787db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch:  0\n",
      "Training loss:  tensor(0.5151, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.7632)\n",
      "Test Accuracy:  tensor(0.6355)\n",
      "Starting epoch:  1\n",
      "Training loss:  tensor(0.3930, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.8304)\n",
      "Test Accuracy:  tensor(0.6567)\n",
      "Starting epoch:  2\n",
      "Training loss:  tensor(0.3781, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.8389)\n",
      "Test Accuracy:  tensor(0.6653)\n",
      "Starting epoch:  3\n",
      "Training loss:  tensor(0.3696, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.8424)\n",
      "Test Accuracy:  tensor(0.6797)\n",
      "Starting epoch:  4\n",
      "Training loss:  tensor(0.3655, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.8462)\n",
      "Test Accuracy:  tensor(0.6894)\n"
     ]
    }
   ],
   "source": [
    "# LSTM stacked\n",
    "input_dim = 30\n",
    "hidden_dim = 1 \n",
    "layer_dim = 2 \n",
    "output_dim = 1 \n",
    "dropout_prob = 0\n",
    "fc_dim = 500\n",
    "lstm = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim, dropout_prob, fc_dim)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(),lr=1e-2,weight_decay=0)\n",
    "lstm.double()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "# Train\n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    for epoch in range(5):\n",
    "        lstm.train()\n",
    "        print('Starting epoch: ', epoch)\n",
    "        running_loss = 0\n",
    "        for i in range(0, train.shape[0], 64):\n",
    "            optimizer.zero_grad()\n",
    "            data = train[i:i+64]\n",
    "            y = data[:,:,1]\n",
    "            y[y<0] = 0\n",
    "            y[y>0] = 1\n",
    "            y = y.mean(axis=1)\n",
    "            y = np.round_(y)\n",
    "            y = torch.tensor(y)\n",
    "            input = torch.tensor(data[:,:,2:])\n",
    "            output = lstm(input)\n",
    "            loss = criterion(output.flatten(), y)\n",
    "            loss.backward()     \n",
    "            optimizer.step()\n",
    "            \n",
    "        running_loss = test_model(lstm, 'train loss')\n",
    "        train_accuracy = test_model(lstm, 'train accuracy')\n",
    "        test_accuracy = test_model(lstm, 'test accuracy')\n",
    "        train_loss.append(train_accuracy)\n",
    "        test_loss.append(test_accuracy)\n",
    "        print('Training loss: ', running_loss)\n",
    "        print('Training Accuracy: ', train_accuracy)\n",
    "        print('Test Accuracy: ', test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f913f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch:  0\n",
      "Training loss:  tensor(0.4719, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.8018)\n",
      "Test Accuracy:  tensor(0.7255)\n",
      "Starting epoch:  1\n",
      "Training loss:  tensor(0.4019, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.8299)\n",
      "Test Accuracy:  tensor(0.7330)\n",
      "Starting epoch:  2\n",
      "Training loss:  tensor(0.3861, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.8362)\n",
      "Test Accuracy:  tensor(0.7192)\n",
      "Starting epoch:  3\n",
      "Training loss:  tensor(0.3760, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.8426)\n",
      "Test Accuracy:  tensor(0.7060)\n",
      "Starting epoch:  4\n",
      "Training loss:  tensor(0.3699, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.8451)\n",
      "Test Accuracy:  tensor(0.7089)\n"
     ]
    }
   ],
   "source": [
    "# LSTM stacked\n",
    "input_dim = 30\n",
    "hidden_dim = 1 \n",
    "layer_dim = 3\n",
    "output_dim = 1 \n",
    "dropout_prob = 0\n",
    "fc_dim = 500\n",
    "lstm = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim, dropout_prob, fc_dim)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(),lr=1e-2,weight_decay=0)\n",
    "lstm.double()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "# Train\n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    for epoch in range(5):\n",
    "        lstm.train()\n",
    "        print('Starting epoch: ', epoch)\n",
    "        running_loss = 0\n",
    "        for i in range(0, train.shape[0], 64):\n",
    "            optimizer.zero_grad()\n",
    "            data = train[i:i+64]\n",
    "            y = data[:,:,1]\n",
    "            y[y<0] = 0\n",
    "            y[y>0] = 1\n",
    "            y = y.mean(axis=1)\n",
    "            y = np.round_(y)\n",
    "            y = torch.tensor(y)\n",
    "            input = torch.tensor(data[:,:,2:])\n",
    "            output = lstm(input)\n",
    "            loss = criterion(output.flatten(), y)\n",
    "            loss.backward()     \n",
    "            optimizer.step()\n",
    "            \n",
    "        running_loss = test_model(lstm, 'train loss')\n",
    "        train_accuracy = test_model(lstm, 'train accuracy')\n",
    "        test_accuracy = test_model(lstm, 'test accuracy')\n",
    "        train_loss.append(train_accuracy)\n",
    "        test_loss.append(test_accuracy)\n",
    "        print('Training loss: ', running_loss)\n",
    "        print('Training Accuracy: ', train_accuracy)\n",
    "        print('Test Accuracy: ', test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70f15c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch:  0\n",
      "Training loss:  tensor(0.5898, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.7058)\n",
      "Test Accuracy:  tensor(0.6052)\n",
      "Starting epoch:  1\n",
      "Training loss:  tensor(0.4449, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.7966)\n",
      "Test Accuracy:  tensor(0.7146)\n",
      "Starting epoch:  2\n",
      "Training loss:  tensor(0.3992, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.8216)\n",
      "Test Accuracy:  tensor(0.7181)\n",
      "Starting epoch:  3\n",
      "Training loss:  tensor(0.3870, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.8267)\n",
      "Test Accuracy:  tensor(0.7278)\n",
      "Starting epoch:  4\n",
      "Training loss:  tensor(0.3797, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.8296)\n",
      "Test Accuracy:  tensor(0.7358)\n"
     ]
    }
   ],
   "source": [
    "# LSTM not stacked\n",
    "input_dim = 30\n",
    "hidden_dim = 1 \n",
    "layer_dim = 1 \n",
    "output_dim = 1 \n",
    "dropout_prob = 0\n",
    "fc_dim = 500\n",
    "lstm = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim, dropout_prob, fc_dim)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(),lr=1e-2,weight_decay=0)\n",
    "lstm.double()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "# Train\n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    for epoch in range(5):\n",
    "        lstm.train()\n",
    "        print('Starting epoch: ', epoch)\n",
    "        running_loss = 0\n",
    "        for i in range(0, train.shape[0], 64):\n",
    "            optimizer.zero_grad()\n",
    "            data = train[i:i+64]\n",
    "            y = data[:,:,1]\n",
    "            y[y<0] = 0\n",
    "            y[y>0] = 1\n",
    "            y = y.mean(axis=1)\n",
    "            y = np.round_(y)\n",
    "            y = torch.tensor(y)\n",
    "            input = torch.tensor(data[:,:,2:])\n",
    "            output = lstm(input)\n",
    "            loss = criterion(output.flatten(), y)\n",
    "            loss.backward()     \n",
    "            optimizer.step()\n",
    "            \n",
    "        running_loss = test_model(lstm, 'train loss')\n",
    "        train_accuracy = test_model(lstm, 'train accuracy')\n",
    "        test_accuracy = test_model(lstm, 'test accuracy')\n",
    "        train_loss.append(train_accuracy)\n",
    "        test_loss.append(test_accuracy)\n",
    "        print('Training loss: ', running_loss)\n",
    "        print('Training Accuracy: ', train_accuracy)\n",
    "        print('Test Accuracy: ', test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3763af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch:  0\n",
      "Training loss:  tensor(0.7133, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.5397)\n",
      "Test Accuracy:  tensor(0.5673)\n",
      "Starting epoch:  1\n",
      "Training loss:  tensor(0.7019, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.5958)\n",
      "Test Accuracy:  tensor(0.6029)\n",
      "Starting epoch:  2\n",
      "Training loss:  tensor(0.5127, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.7721)\n",
      "Test Accuracy:  tensor(0.4854)\n",
      "Starting epoch:  3\n",
      "Training loss:  tensor(0.4528, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.7964)\n",
      "Test Accuracy:  tensor(0.5524)\n",
      "Starting epoch:  4\n",
      "Training loss:  tensor(0.4371, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.8043)\n",
      "Test Accuracy:  tensor(0.5885)\n"
     ]
    }
   ],
   "source": [
    "# GRU\n",
    "input_dim = 30\n",
    "hidden_dim = 1 \n",
    "layer_dim = 1 \n",
    "output_dim = 1 \n",
    "dropout_prob = 0\n",
    "fc_dim = 500\n",
    "gru = GRUModel(input_dim, hidden_dim, layer_dim, output_dim, dropout_prob, fc_dim)\n",
    "optimizer = torch.optim.Adam(gru.parameters(),lr=1e-2,weight_decay=0)\n",
    "gru.double()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "# Train\n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    for epoch in range(5):\n",
    "        gru.train()\n",
    "        print('Starting epoch: ', epoch)\n",
    "        running_loss = 0\n",
    "        for i in range(0, train.shape[0], 64):\n",
    "            optimizer.zero_grad()\n",
    "            data = train[i:i+64]\n",
    "            y = data[:,:,1]\n",
    "            y[y<0] = 0\n",
    "            y[y>0] = 1\n",
    "            y = y.mean(axis=1)\n",
    "            y = np.round_(y)\n",
    "            y = torch.tensor(y)\n",
    "            input = torch.tensor(data[:,:,2:])\n",
    "            output = gru(input)\n",
    "            loss = criterion(output.flatten(), y)\n",
    "            loss.backward()     \n",
    "            optimizer.step()\n",
    "            \n",
    "        running_loss = test_model(gru, 'train loss')\n",
    "        train_accuracy = test_model(gru, 'train accuracy')\n",
    "        test_accuracy = test_model(gru, 'test accuracy')\n",
    "        train_loss.append(train_accuracy)\n",
    "        test_loss.append(test_accuracy)\n",
    "        print('Training loss: ', running_loss)\n",
    "        print('Training Accuracy: ', train_accuracy)\n",
    "        print('Test Accuracy: ', test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61faf06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch:  0\n",
      "Training loss:  tensor(0.6744, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.6124)\n",
      "Test Accuracy:  tensor(0.6579)\n",
      "Starting epoch:  1\n",
      "Training loss:  tensor(0.4847, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.7867)\n",
      "Test Accuracy:  tensor(0.6023)\n",
      "Starting epoch:  2\n",
      "Training loss:  tensor(0.4486, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.8034)\n",
      "Test Accuracy:  tensor(0.6206)\n",
      "Starting epoch:  3\n",
      "Training loss:  tensor(0.4291, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.8127)\n",
      "Test Accuracy:  tensor(0.6275)\n",
      "Starting epoch:  4\n",
      "Training loss:  tensor(0.4159, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Training Accuracy:  tensor(0.8196)\n",
      "Test Accuracy:  tensor(0.6424)\n"
     ]
    }
   ],
   "source": [
    "# GRU\n",
    "input_dim = 30\n",
    "hidden_dim = 1 \n",
    "layer_dim = 2 \n",
    "output_dim = 1 \n",
    "dropout_prob = 0\n",
    "fc_dim = 500\n",
    "gru = GRUModel(input_dim, hidden_dim, layer_dim, output_dim, dropout_prob, fc_dim)\n",
    "optimizer = torch.optim.Adam(gru.parameters(),lr=1e-2,weight_decay=0)\n",
    "gru.double()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "# Train\n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    for epoch in range(5):\n",
    "        gru.train()\n",
    "        print('Starting epoch: ', epoch)\n",
    "        running_loss = 0\n",
    "        for i in range(0, train.shape[0], 64):\n",
    "            optimizer.zero_grad()\n",
    "            data = train[i:i+64]\n",
    "            y = data[:,:,1]\n",
    "            y[y<0] = 0\n",
    "            y[y>0] = 1\n",
    "            y = y.mean(axis=1)\n",
    "            y = np.round_(y)\n",
    "            y = torch.tensor(y)\n",
    "            input = torch.tensor(data[:,:,2:])\n",
    "            output = gru(input)\n",
    "            loss = criterion(output.flatten(), y)\n",
    "            loss.backward()     \n",
    "            optimizer.step()\n",
    "            \n",
    "        running_loss = test_model(gru, 'train loss')\n",
    "        train_accuracy = test_model(gru, 'train accuracy')\n",
    "        test_accuracy = test_model(gru, 'test accuracy')\n",
    "        train_loss.append(train_accuracy)\n",
    "        test_loss.append(test_accuracy)\n",
    "        print('Training loss: ', running_loss)\n",
    "        print('Training Accuracy: ', train_accuracy)\n",
    "        print('Test Accuracy: ', test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09efd05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, mode):\n",
    "    model.eval()\n",
    "    if mode == 'test accuracy':\n",
    "        out = model(torch.tensor(test[:,:,2:]))\n",
    "        out = out.flatten()\n",
    "        y = test[:,:,1]\n",
    "        y[y<0] = 0\n",
    "        y[y>0] = 1\n",
    "        y = y.mean(axis=1)\n",
    "        y = np.round_(y)\n",
    "        y = torch.tensor(y)\n",
    "        accuracy = torch.sum(torch.round(out.flatten()) == y)/y.shape[0]\n",
    "        return accuracy\n",
    "    elif mode == 'train accuracy':\n",
    "        out = model(torch.tensor(train[:,:,2:]))\n",
    "        out = out.flatten()\n",
    "        y = train[:,:,1]\n",
    "        y[y<0] = 0\n",
    "        y[y>0] = 1\n",
    "        y = y.mean(axis=1)\n",
    "        y = np.round_(y)\n",
    "        y = torch.tensor(y)\n",
    "        accuracy = torch.sum(torch.round(out.flatten()) == y)/y.shape[0]\n",
    "        return accuracy\n",
    "    elif mode == 'train loss':\n",
    "        criterion = nn.BCELoss()\n",
    "        out = model(torch.tensor(train[:,:,2:]))\n",
    "        out = out.flatten()\n",
    "        y = train[:,:,1]\n",
    "        y[y<0] = 0\n",
    "        y[y>0] = 1\n",
    "        y = y.mean(axis=1)\n",
    "        y = np.round_(y)\n",
    "        y = torch.tensor(y)\n",
    "        return criterion(out.flatten(), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaac5b4",
   "metadata": {},
   "source": [
    "Ideas: try CNN-RNN architecture of CNN-LSTM architecture, deeper FC architecture, try regularization methods, try transfer learning by splitting our dataset, data augmentation, larger windows\n",
    "\n",
    "Do we want to detect or predict FOG?\n",
    "In patient or out patient prediction (do we assume we have some or no data of the patient FOG to be predicted)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3961b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
